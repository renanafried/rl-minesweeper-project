# Minesweeper RL Agent

This project implements an AI agent for playing Minesweeper using a combination of:
- A rule-based logic solver
- Supervised pretraining using solver-generated data
- Reinforcement Learning with Monte Carlo Policy Gradient (REINFORCE)

It includes a full environment, training pipeline, pretrained models, and visualization of performance.

---

## What is Minesweeper?

Minesweeper is a logic-based puzzle game played on a hidden grid of cells. Some cells contain hidden mines, and the rest are safe.  
The player uncovers cells and uses numerical clues (showing how many mines are adjacent) to deduce the locations of mines.  
The goal is to uncover all safe cells without clicking on a mine. If a mine is clicked, the game ends immediately.

---

## Project Components

- `mc_agent.py` – Neural network and Monte Carlo-based agent logic.
- `minesweeper_env.py` – Custom Gym-compatible environment for Minesweeper.
- `rotate_utils.py` – Data augmentation: rotation of board states and actions.
- `solver.py` – Rule-based logic solver to identify provably safe moves.
- `solver_data_generator.py` – Generates training data using the solver.
- `train_mc.py` – Main training script using Monte Carlo reinforcement learning.
- `.pt` files:
  - `pretrained_supervised.pt` – From supervised training using the solver.
  - `mc_final.pt` – From reinforcement learning.
- `solver_data.npz` – Dataset generated by the solver for supervised learning.

---

## Setup & Installation

Make sure you have Python 3.8+ installed.

To install the required packages, run:

```bash
pip install -r requirements.txt
```

> The file `requirements.txt` includes specific library versions to ensure reproducibility:
> - numpy==1.24.3  
> - torch==2.0.1  
> - matplotlib==3.7.1  
> - gym==0.26.2

---

## How to Run

There are two main training stages in this project:

### 1. Supervised Pretraining

```bash
python solver_data_generator.py
```

This script:
- Simulates games using logic-based safe moves
- Generates `solver_data.npz`
- Trains a classifier to imitate solver behavior
- Saves model to `pretrained_supervised.pt`

### 2. Reinforcement Learning (Monte Carlo)

```bash
python train_mc.py
```

This script:
- Loads `pretrained_supervised.pt` if available
- Trains agent with Monte Carlo policy gradient (REINFORCE)
- Updates model only after successful episodes
- Saves final model to `mc_final.pt`
- Creates performance graphs in `graphs/`

> You can stop and resume training safely — it will reload from saved model.

---

## Output Graphs

After training, the following graphs are saved to the `graphs/` folder:

- Rolling average reward
- Rolling win rate
- Steps per episode (failures and successes)
- Cumulative win rate over time
- Success rate: first 100 vs. last 100 episodes

---

## Reproducibility

- Board size: 5×5  
- Number of mines: 3  
- Valid action masking  
- Rotation-based data augmentation

---

## Authors

Hadar Niv, Yarden Samuel, Dvir Friedman, Renana Fried  
Final Project – Industrial Engineering & Management  
Ariel University, 2025
